{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7534431",
   "metadata": {},
   "source": [
    "**Note This notebook is currently broken, due to migration and updates of posggym and posggym.agents.**\n",
    "\n",
    "# POSGGym.agents policy analysis\n",
    "\n",
    "This script can be used for visualizing the pairwise performance of implemented policies.\n",
    "\n",
    "The actual results files are stored in the `posggym/notebooks/results` directory.\n",
    "\n",
    "\n",
    "## Notation\n",
    "\n",
    "- **Same-play** refers to pairings of policies that are trained together or at least trained as part of the same population\n",
    "- **Cross-play** refers to pairings of policies that were not trained together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import posggym\n",
    "\n",
    "from posggym.agents.registration import parse_policy_id\n",
    "from posggym.config import REPO_DIR\n",
    "\n",
    "sys.path.append(osp.join(REPO_DIR, \"notebooks\"))\n",
    "import plot_utils\n",
    "\n",
    "results_dir = osp.join(REPO_DIR, \"notebooks\", \"results\")\n",
    "\n",
    "available_result_files = os.listdir(results_dir)\n",
    "available_result_files.sort()\n",
    "\n",
    "print(\"Available Env Results\")\n",
    "print(\"---------------------\")\n",
    "for file_name in available_result_files:\n",
    "    print(file_name.split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12808fe8",
   "metadata": {},
   "source": [
    "## The environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252c8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CHANGE THIS\n",
    "env_id = \"PredatorPrey-10x10-P2-p3-s2-coop-v0\"\n",
    "assert f\"{env_id}.csv\" in os.listdir(results_dir)\n",
    "env_result_file = osp.join(results_dir, f\"{env_id}.csv\")\n",
    "\n",
    "# display environment\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "env = posggym.make(env_id, render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "env_img = env.render()\n",
    "\n",
    "imshow_obj = ax.imshow(env_img, interpolation='bilinear', origin='upper')\n",
    "imshow_obj.set_data(env_img)\n",
    "\n",
    "ax.set_title(env_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5571e8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_info(df: pd.DataFrame):\n",
    "    for k in [\"agent_id\", \"policy_seed\", \"policy_type\"]:\n",
    "        values = df[k].unique().tolist()\n",
    "        values.sort()\n",
    "        print(f\"{k}: {values}\")\n",
    "\n",
    "    policy_ids = df[\"policy_id\"].unique().tolist()\n",
    "    policy_ids.sort()\n",
    "    print(\"\\nPolicy IDs\")\n",
    "    print(\"----------\")\n",
    "    for pi_id in policy_ids:\n",
    "        print(pi_id)\n",
    "        \n",
    "    team_ids = df[\"co_team_id\"].unique().tolist()\n",
    "    team_ids.sort()\n",
    "    print(\"\\nCo-player Team IDs\")\n",
    "    print(\"------------------\")\n",
    "    for t_id in team_ids:\n",
    "        print(t_id)\n",
    "        \n",
    "    team_seeds = df[\"co_team_seed\"].unique().tolist()\n",
    "    team_seeds.sort()\n",
    "    print(\"\\nCo-player Team Seeds\")\n",
    "    print(\"--------------------\")\n",
    "    print(team_seeds)\n",
    "    \n",
    "    team_types = df[\"co_team_type\"].unique().tolist()\n",
    "    team_types.sort()\n",
    "    print(\"\\nCo-player Team Types\")\n",
    "    print(\"--------------------\")\n",
    "    print(team_types)\n",
    "\n",
    "    print(\"\\nColumns\")\n",
    "    print(\"-------\")\n",
    "    for c in df.columns:\n",
    "        print(c)\n",
    "        \n",
    "\n",
    "def add_95CI(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add 95% CI columns to dataframe.\"\"\"\n",
    "\n",
    "    def conf_int(row, prefix):\n",
    "        std = row[f\"{prefix}_std\"]\n",
    "        n = row[\"num_episodes\"]\n",
    "        return 1.96 * (std / np.sqrt(n))\n",
    "\n",
    "    prefix = \"\"\n",
    "    for col in df.columns:\n",
    "        if not col.endswith(\"_std\"):\n",
    "            continue\n",
    "        prefix = col.replace(\"_std\", \"\")\n",
    "        df[f\"{prefix}_CI\"] = df.apply(lambda row: conf_int(row, prefix), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_outcome_proportions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add proportion columns to dataframe.\"\"\"\n",
    "\n",
    "    def prop(row, col_name):\n",
    "        n = row[\"num_episodes\"]\n",
    "        total = row[col_name]\n",
    "        return total / n\n",
    "\n",
    "    columns = [\"num_LOSS\", \"num_DRAW\", \"num_WIN\", \"num_NA\"]\n",
    "    new_column_names = [\"prop_LOSS\", \"prop_DRAW\", \"prop_WIN\", \"prop_NA\"]\n",
    "    for col_name, new_name in zip(columns, new_column_names):\n",
    "        if col_name in df.columns:\n",
    "            df[new_name] = df.apply(lambda row: prop(row, col_name), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_df_policy_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove environment name from policy ID, if it's present.\"\"\"\n",
    "\n",
    "    def clean(row):\n",
    "        if \"/\" in row[\"policy_id\"]:\n",
    "            return row[\"policy_id\"].split(\"/\")[1]\n",
    "        return row[\"policy_id\"]\n",
    "\n",
    "    df[\"policy_id\"] = df.apply(clean, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_df_coplayer_policy_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add co-player policy IDs to dataframe.\n",
    "\n",
    "    Adds a new column for each agent in the environment:\n",
    "\n",
    "      coplayer_policy_id_0, coplayer_policy_id_1, ..., coplayer_policy_id_N\n",
    "\n",
    "    Each column contains the policy_id of the agent with corresponding ID for\n",
    "    the given experiment. \n",
    "    \n",
    "    This includes the row agent so if the row[\"agent_id\"] = i\n",
    "    then row[\"coplayer_policy_id_i\"] = row[\"policy_id\"]\n",
    "\n",
    "    \"\"\"\n",
    "    agent_ids = df[\"agent_id\"].unique().tolist()\n",
    "    agent_ids.sort()\n",
    "\n",
    "    dfs = [df[df[\"agent_id\"] == i] for i in agent_ids]\n",
    "    for i, df_i in zip(agent_ids, dfs):\n",
    "        for j, df_j in zip(agent_ids, dfs):\n",
    "            df_i[f\"coplayer_policy_id_{j}\"] = df_i[\"exp_id\"].map(\n",
    "                df_j.set_index(\"exp_id\")[\"policy_id\"].to_dict()\n",
    "            )\n",
    "    return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def add_policy_seed(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add policy seeds to dataframe.\"\"\"\n",
    "\n",
    "    def policy_seed(row, id_key):\n",
    "        _, pi_name, _ = parse_policy_id(row[id_key])\n",
    "        if \"_seed\" in pi_name:\n",
    "            seed_token = [t for t in pi_name.split(\"_\") if t.startswith(\"seed\")][0]\n",
    "            return int(seed_token.replace(\"seed\", \"\"))\n",
    "        return 0\n",
    "\n",
    "    df[\"policy_seed\"] = df.apply(lambda row: policy_seed(row, \"policy_id\"), axis=1)\n",
    "    \n",
    "    agent_ids = df[\"agent_id\"].unique().tolist()\n",
    "    agent_ids.sort()\n",
    "    for j in agent_ids:\n",
    "        df[f\"coplayer_policy_seed_{j}\"] = df.apply(\n",
    "            lambda row: policy_seed(row, f\"coplayer_policy_id_{j}\"), axis=1\n",
    "        )    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_policy_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add policy types to dataframe.\"\"\"\n",
    "\n",
    "    def policy_type(row, id_key):\n",
    "        _, pi_name, _ = parse_policy_id(row[id_key])\n",
    "        type_tokens = [t for t in pi_name.split(\"_\") if not t.startswith(\"seed\")]\n",
    "        return \"_\".join(type_tokens)\n",
    "\n",
    "    df[\"policy_type\"] = df.apply(lambda row: policy_type(row, \"policy_id\"), axis=1)\n",
    "    agent_ids = df[\"agent_id\"].unique().tolist()\n",
    "    agent_ids.sort()\n",
    "    for j in agent_ids:\n",
    "        df[f\"coplayer_policy_type_{j}\"] = df.apply(\n",
    "            lambda row: policy_type(row, f\"coplayer_policy_id_{j}\"), axis=1\n",
    "        ) \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_co_team_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add coplayer team ID column to dataframe.\"\"\"\n",
    "    agent_ids = df[\"agent_id\"].unique().tolist()\n",
    "    agent_ids.sort()\n",
    "\n",
    "    def get_team_id(row):\n",
    "        i = row[\"agent_id\"]\n",
    "        pi_ids = [\n",
    "            row[f\"coplayer_policy_id_{j}\"] \n",
    "            for j in agent_ids if j != i\n",
    "        ]\n",
    "        return tuple(pi_ids)\n",
    "    \n",
    "    def get_team_seed(row):\n",
    "        i = row[\"agent_id\"]\n",
    "        pi_seeds = [\n",
    "            row[f\"coplayer_policy_seed_{j}\"] \n",
    "            for j in agent_ids if j != i\n",
    "        ]\n",
    "        return tuple(pi_seeds)\n",
    "    \n",
    "    def get_team_type(row):\n",
    "        i = row[\"agent_id\"]\n",
    "        pi_types = [\n",
    "            row[f\"coplayer_policy_type_{j}\"] \n",
    "            for j in agent_ids if j != i\n",
    "        ]\n",
    "        return tuple(pi_types)\n",
    "\n",
    "    df[\"co_team_id\"] = df.apply(get_team_id, axis=1)\n",
    "    df[\"co_team_seed\"] = df.apply(get_team_seed, axis=1)\n",
    "    df[\"co_team_type\"] = df.apply(get_team_type, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_results(result_file: str,) -> pd.DataFrame:\n",
    "    \"\"\"Import experiment results.\"\"\"\n",
    "    # disable annoying warning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    df = pd.read_csv(result_file)\n",
    "\n",
    "    df = add_95CI(df)\n",
    "    df = add_outcome_proportions(df)\n",
    "    df = clean_df_policy_ids(df)\n",
    "    df = add_df_coplayer_policy_ids(df)\n",
    "    df = add_policy_seed(df)\n",
    "    df = add_policy_type(df)\n",
    "    df = add_co_team_id(df)\n",
    "    \n",
    "    # enable annoyin warning\n",
    "    pd.options.mode.chained_assignment = \"warn\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627defa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = import_results(env_result_file)\n",
    "display_df_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09d5e1",
   "metadata": {},
   "source": [
    "## Pairwise Performance\n",
    "\n",
    "Here we look at the performance for each possible pairing of policies.\n",
    "\n",
    "For each performance metric we have a grid of (grid)-plots:\n",
    "    \n",
    "- Outer-grid: train seed X train seed\n",
    "- Inner-grid: policy_id X policy_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eddd9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_width = len(df[\"co_team_id\"].unique()) // 1.5\n",
    "fig_height = len(df[\"policy_id\"].unique()) // 1.5\n",
    "\n",
    "plot_utils.plot_pairwise_comparison(\n",
    "    df, \n",
    "    y_key=\"episode_return_mean\", \n",
    "    policy_key=\"policy_id\",\n",
    "    coplayer_policy_key=\"co_team_id\",\n",
    "    vrange=None, \n",
    "    figsize=(fig_width, fig_height), \n",
    "    valfmt=\"{x:.2f}\",\n",
    "    average_duplicates=True,\n",
    "    duplicate_warning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16258dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this may fail for some environments.\n",
    "# if it does just move to the next plot (i.e. average pop performance)\n",
    "\n",
    "fig_width = max(9, len(df[\"co_team_seed\"].unique()) * len(df[\"co_team_type\"].unique()) // 1.5)\n",
    "fig_height = max(9, len(df[\"policy_seed\"].unique()) * len(df[\"policy_type\"].unique()) // 1.5)\n",
    "\n",
    "fig, axs = plot_utils.plot_pairwise_population_comparison(\n",
    "    df, \n",
    "    y_key=\"episode_return_mean\", \n",
    "    pop_key=\"policy_seed\",\n",
    "    policy_key=\"policy_type\",\n",
    "    coplayer_pop_key=\"co_team_seed\",\n",
    "    coplayer_policy_key=\"co_team_type\",\n",
    "    vrange=None, \n",
    "    figsize=(fig_width, fig_height),\n",
    "    valfmt=\"{x:.2f}\",\n",
    "    average_duplicates=True,\n",
    "    duplicate_warning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1107c",
   "metadata": {},
   "source": [
    "### Average performance\n",
    "\n",
    "Here we look at average performance of the policies.\n",
    "\n",
    "Each plot shows the *mean performance* for the *row* policy against the *column* policy.\n",
    "\n",
    "The **left-hand plot** shows *same-play* performance. So performance of policies against policies from the same training population. With the values shown being the mean over all populations.\n",
    "\n",
    "The **middle plot** shows *cross-play* performance. So performance of policies against policies from different training populations. With the values shown being the mean over all populations.\n",
    "\n",
    "The **right-hand plot** shows the generalization gap which is just the difference between the *Same-Play* and *Cross-Play* performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_width = max(12, (len(df[\"co_team_type\"].unique()) // 1.25) * 3)\n",
    "fig_height = max(6, len(df[\"policy_type\"].unique()) // 1.25)\n",
    "\n",
    "for y_key in [\"episode_return_mean\", \"prop_WIN\", \"prop_LOSS\"]:\n",
    "    plot_utils.plot_mean_pairwise_comparison(\n",
    "        df, \n",
    "        y_key=y_key, \n",
    "        policy_key=\"policy_type\",\n",
    "        pop_key=\"policy_seed\",\n",
    "        coplayer_pop_key=\"co_team_seed\",\n",
    "        coplayer_policy_key=\"co_team_type\",\n",
    "        vrange=None, \n",
    "        figsize=(fig_width, fig_height), \n",
    "        valfmt=\"{x:.2f}\"\n",
    "    )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posggym",
   "language": "python",
   "name": "posggym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
