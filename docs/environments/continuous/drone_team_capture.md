---
autogenerated:
title: Drone Team Capture
firstpage:
---

# Drone Team Capture



This environment is part of the <a href='..'>Continuous environments</a>. Please read that page first for general information.

|   |   |
|---|---|
| Possible Agents | ('0', '1', '2') |
| Action Spaces | {'0': Box(-1.0, 1.0, (1,), float32), '1': Box(-1.0, 1.0, (1,), float32), '2': Box(-1.0, 1.0, (1,), float32)} |
| Observation Spaces | {'0': Box(-inf, inf, (10,), float32), '1': Box(-inf, inf, (10,), float32), '2': Box(-inf, inf, (10,), float32)} |
| Symmetric | True |
| Import | `posggym.make("DroneTeamCapture-v0")` |


The Drone Team Capture Environment.

A co-operative 2D continuous world problem involving multiple pursuer drone agents
working together to catch a target agent in the environment.

Possible Agents
---------------
Varied number (1-8)

State Space
-----------
Each state consists of:

1. tuple of the (x, y) position of all pursuers
2. tuple of the (x, y) previous position of all pursuers
3. tuple of the (x, y) position of the target
4. tuple of the (x, y) previous position of the target
5. The speed of the target relative to the pursuer (0.0 -> 2.0)

For the coordinate x=column, y=row, with the origin (0, 0) at the
top-left square of the world.

Action Space
------------
Each agent has either 1 or 2 actions. If 'velocity_control=False' then the agent
can only control their angular velocity. If 'velocity_control=True' then the agent
has two actions, which are the angular and linear velocity, in that order.

Observation Space
-----------------
Each agent observes the other pursuers and target. For each pursuer they will
observe the relative position and angle of the pursuer. They will observe
their own heading and change in heading. They will also observe the distance
to the target, and the angle to the target, as well as, their derivatives.
The pursuers will be ordered by the relative distance to the target.

However, there are two parameters to change this behaviour. Firstly,
`observation_limit` which specifies the maximum distance another agent can be seen.
If they are outside this radius, the observations of these agents will be `-1`.

There is also the `n_communicating_purusers` which will limit the maximum amount of
other pursuers an agent can observe.

Rewards
-------
Each pursuer will receive a reward based on the Q parameter and the distance from
the target. On successful capture, the capturing pursuer will receive a reward of
`+130`, while other agents will receive `100`.

Dynamics
--------
Actions of the puruser agents are deterministic and consist of moving based on the
non-holonomic model.

The target will move following a holonomic model TODO

Starting State
--------------
Target will start near the outside of the circle, while pursuers will start in a
line on the middle. The pursuers will start with a random yaw.

Episodes End
------------
Episodes ends when the target has been captured. By default a `max_episode_steps`
limit of `50` steps is also set. This may need to be adjusted when using larger
grids (this can be done by manually specifying a value for `max_episode_steps`when
creating the environment with `posggym.make`).

Arguments
---------

- `num_agents` - The number of agents which exist in the environment
    Must be between 1 and 8 (default = `3`)
- `n_communicating_puruser - The maximum number of agents which an
    agent can receive information from (default = `3`)
- `velocity_control` - If the agents have control of their linear velocity
    (default = `False`)
- `arena_size` - Size of the arena (default = `430`)
- `observation_limit` - The limit of which agents can see other agents
    (default = `430`)
- `use_curriculum` - If curriculum learning is used, a large capture radius is used
    the capture radius needs to be decreased using the 'decrease_cap_rad' function
    (default = `False`)

Available variants
------------------

For example to use the Drone Team Capture environment with 8 communicating pursuers
and episode step limit of 100, and the default values for the other parameters
(`velocity_control`, `arena_size`, `observation_limit`, `use_curriculum`) you would
use:

```python
import posggym
env = posgggym.make(
    'DroneTeamCapture-v0',
    max_episode_steps=100,
    num_agents=8,
    n_communicating_puruser=4,
)
```

Version History
---------------
- `v0`: Initial version
