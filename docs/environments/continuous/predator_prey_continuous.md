---
autogenerated:
title: Predator Prey Continuous
lastpage:
---

# Predator Prey Continuous



This environment is part of the <a href='..'>Continuous environments</a>. Please read that page first for general information.

|   |   |
|---|---|
| Possible Agents | ('0', '1') |
| Action Spaces | {'0': Box(-1.0, 1.0, (2,), float32), '1': Box(-1.0, 1.0, (2,), float32)} |
| Observation Spaces | {'0': Tuple(Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32)), '1': Tuple(Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32), Discrete(4), Box(0.0, 30.0, (1,), float32))} |
| Symmetric | True |
| Import | `posggym.make("PredatorPreyContinuous-v0")` |


The Continuous Predator-Prey Environment.

A co-operative 2D continuous world problem involving multiple predator agents
working together to catch prey agent/s in the environment.

Possible Agents
---------------
Varied number

State Space
-----------
Each state consists of:

1. tuple of the (x, y) position of all predators
2. tuple of the (x, y) position of all preys
3. tuple of whether each prey has been caught or not (0=no, 1=yes)

For the coordinate x=column, y=row, with the origin (0, 0) at the top-left square
of the world.

Action Space
------------
Each agent has 2 actions. In the `holonomic` model there are two actions, which
are the change in x and change in y position. In the non-holonomic model, there
are also two actions, which are the angular and linear velocity.

Observation Space
-----------------
Each agent observes the contents of local cells. This is achieved by
a series of 'n_lines' lines starting at the agent which extend for a distance of
'obs_dim'. For each line the agent observes whether they intersect with one of four
objects: `EMPTY=0`, `WALL=1`, `PREDATOR=2`, `PREY=3`. They also observe the distance
to the object. If the object is `EMPTY=0`, the distance will always be equal to
'obs_dim'

Rewards
-------
There are two modes of play:

1. *Fully cooperative*: All predators share a reward and each agent receives
a reward of `1.0 / num_prey` for each prey capture, independent of which
predator agent/s were responsible for the capture.

2. *Mixed cooperative*: Predators only receive a reward if they were part
of the prey capture, receiving `1.0 / num_prey` per capture.

In both modes prey can only been captured when at least `prey_strength`
predators are in adjacent cells, where `1 <= prey_strength <= num_predators`.

Dynamics
--------
Actions of the predator agents are deterministic and consist of moving based on
the dynamic model. If two or more predators attempt to move into the same location
then no agent moves.

Prey move according to the following rules (in order of priority):

1. if predator is within `obs_dim` distance, moves away from closest predator
2. if another prey is within `obs_dim` distance, moves away from closest prey
3. else move randomly

Prey always move first and predators and prey cannot occupy the same location.
The only exception being if a prey has been caught their final coord is
recorded in the state but predator and prey agents will be able to move
into the final coord.

Starting State
--------------
Predators start from random separate locations along the edge of the world
(either in a corner, or half-way along a side), while prey start together
in the middle.

Episodes End
------------
Episodes ends when all prey have been captured. By default a `max_episode_steps`
limit of `50` steps is also set. This may need to be adjusted when using larger
grids (this can be done by manually specifying a value for `max_episode_steps` when
creating the environment with `posggym.make`).

Arguments
---------

- `grid` - the grid layout to use. This can either be a string specifying one of
     the supported grids, or a custom :class:`PPWorld` object (default = `"10x10"`).
- `num_predators` - the number of predator (and thus controlled agents)
    (default = `2`).
- `num_prey` - the number of prey (default = `3`)
- `cooperative` - whether agents share all rewards or only get rewards for prey they
    are involved in capturing (default = 'True`)
- `prey_strength` - how many predators are required to capture each prey, minimum is
    `1` and maximum is `min(4, num_predators)`. If `None` this is set to
    `min(4, num_predators)` (default = 'None`)
- `obs_dim` - the local observation distance, specifying how far away in each
    direction each predator and prey agent observes (default = `2`).
- `n_lines` - the number of lines eminating from the agent. The agent will observe
    at `n` equidistance intervals over `[0, 2*pi]` (default = `10`).
- `use_holonomic` - the movement model to use. There are two modes - holonomic or
    non holonmic, with a unicycle model (default = 'true`).

Available variants
------------------

The PredatorPrey environment comes with a number of pre-built grid layouts which can
be passed as an argument to `posggym.make`, to create different grids. All layouts
support 2 to 8 agents.

| Grid name         | Grid size |
|-------------------|-----------|
| `5x5`             | 5x5       |
| `5x5Blocks`       | 5x5       |
| `10x10`           | 10x10     |
| `10x10Blocks`     | 10x10     |
| `15x15`           | 15x15     |
| `15x15Blocks`     | 15x15     |
| `20x20`           | 20x20     |
| `20x20Blocks`     | 20x20     |


For example to use the Predator Prey environment with the `15x15Blocks` grid, 4
predators, 4 prey, and episode step limit of 100, and the default values for the
other parameters (`cooperative`, `obs_dim`, `prey_strength`) you would use:

```python
import posggym
env = posgggym.make(
    'PredatorPreyContinuous-v0',
    max_episode_steps=100,
    grid="15x15Blocks",
    num_predators=4,
    num_prey=4
)
```

Version History
---------------
- `v0`: Initial version

Reference
---------
- Ming Tan. 1993. Multi-Agent Reinforcement Learning: Independent vs. Cooperative
  Agents. In Proceedings of the Tenth International Conference on Machine Learning.
  330–337.
- J. Z. Leibo, V. F. Zambaldi, M. Lanctot, J. Marecki, and T. Graepel. 2017.
  Multi-Agent Reinforcement Learning in Sequential Social Dilemmas. In AAMAS,
  Vol. 16. ACM, 464–473
- Lowe, Ryan, Yi I. Wu, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor
  Mordatch. 2017. “Multi-Agent Actor-Critic for Mixed Cooperative-Competitive
  Environments.” Advances in Neural Information Processing Systems 30.
